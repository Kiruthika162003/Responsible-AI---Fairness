{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayV5i5UfNU3g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 0).astype(int)  # Convert to binary classification (setosa vs others)1 represents the Setosa class and 0 represents the other classes.\n",
        "\n",
        "# For demonstration, we'll create a 'sensitive' attribute artificially\n",
        "# This attribute is considered “sensitive” because it is used to check for potential biases in the model.\n",
        "# Here we assign '0' for sepal length < 5.8 and '1' for sepal length >= 5.8\n",
        "sensitive_attr = (X[:, 0] >= 5.8).astype(int)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(\n",
        "    X, y, sensitive_attr, test_size=0.3, random_state=42 )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a simple RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "nMWWyJOxNXXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean prediction for group with sensitive attribute = 0\n",
        "mean_pred_group_0 = np.mean(y_pred[sensitive_test == 0])\n",
        "\n",
        "# Mean prediction for group with sensitive attribute = 1\n",
        "mean_pred_group_1 = np.mean(y_pred[sensitive_test == 1])\n",
        "\n",
        "# Difference between the two means\n",
        "demographic_parity = mean_pred_group_0 - mean_pred_group_1\n",
        "print(f\"Demographic Parity Difference: {demographic_parity:.2f}\") #close to 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJteht4rEYuW",
        "outputId": "1222251a-1f82-4b11-cdb7-ca8a0e586ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demographic Parity Difference: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Demographic Parity is a fairness metric that measures whether different groups (defined by the sensitive attribute) have similar positive prediction rates. A value close to 0 indicates that the model treats both groups similarly, while a larger absolute value indicates potential bias.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zbXaIQedEjX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  The confusion_matrix function is used to get the counts of true negatives (TN), false positives (FP), false negatives (FN), and true positives (TP) for the specified group.\n",
        "Rate Calculations:\n",
        "\n",
        "TPR (True Positive Rate): Calculated as TPR=TP/TP+FN\n",
        "\n",
        "\n",
        "FPR (False Positive Rate): Calculated as FPR= fp/fp+tn\n",
        "\n",
        "\n",
        "Equalized Odds Difference The differences in TPR and FPR between the two groups are computed to assess fairness.\n",
        "\n"
      ],
      "metadata": {
        "id": "jBk3txqnFFLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate True Positive Rate (TPR) and False Positive Rate (FPR) for each group\n",
        "def calculate_rates(y_true, y_pred, group):\n",
        "     cm = confusion_matrix(y_true[group], y_pred[group], labels=[0, 1])\n",
        "     tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
        "     tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "     fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "     return tpr, fpr\n",
        "tpr_0, fpr_0 = calculate_rates(y_test, y_pred, sensitive_test == 0)\n",
        "tpr_1, fpr_1 = calculate_rates(y_test, y_pred, sensitive_test == 1)\n",
        "equalized_odds_diff = (tpr_0 - tpr_1, fpr_0 - fpr_1)\n",
        "print(f\"Equalized Odds TPR Difference: {equalized_odds_diff[0]:.2f}\")#close to 0\n",
        "print(f\"Equalized Odds FPR Difference: {equalized_odds_diff[1]:.2f}\") #close to 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EACiRT-bNhcc",
        "outputId": "77d6ff58-2b7f-453a-e4c2-0c1bea8c817a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equalized Odds TPR Difference: 1.00\n",
            "Equalized Odds FPR Difference: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate positive rates for each group\n",
        "positive_rate_0 = np.mean(y_pred[sensitive_test == 0])\n",
        "positive_rate_1 = np.mean(y_pred[sensitive_test == 1])\n",
        "\n",
        "# Calculate Disparate Impact\n",
        "disparate_impact = positive_rate_1 / positive_rate_0\n",
        "print(f\"Disparate Impact Ratio: {disparate_impact:.2f}\")#Ratio should be close to 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqq6Kne5GCzv",
        "outputId": "517f1168-c895-41a0-f035-82ac36176d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate Impact Ratio: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Equal Opportunity\n",
        "  #the difference in True Positive Rates (TPR) between the two groups\n",
        "equal_opportunity_diff = tpr_0 - tpr_1\n",
        "print(f\"Equal Opportunity Difference: {equal_opportunity_diff:.2f}\")#close to 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF0Ep3YgN0mQ",
        "outputId": "4a793e51-8dc1-4e89-8111-905899d7a706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equal Opportunity Difference: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictive Parity\n",
        "#The difference in precision between the two groups is calculated to assess fairness\n",
        "#tp/tp+fp\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "from sklearn.calibration import calibration_curve # Import calibration_curve from the correct module\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import numpy as np\n",
        "\n",
        "# Calculate precision and recall for each group\n",
        "precision_0, recall_0, _ = precision_recall_curve(y_test[sensitive_test == 0], y_pred[sensitive_test == 0])\n",
        "precision_1, recall_1, _ = precision_recall_curve(y_test[sensitive_test == 1], y_pred[sensitive_test == 1])\n",
        "\n",
        "# Calculate Predictive Parity Difference\n",
        "predictive_parity_diff = np.abs(np.mean(precision_0) - np.mean(precision_1))\n",
        "print(f\"Predictive Parity Difference: {predictive_parity_diff:.2f}\")#close to 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77ZnOYddQFag",
        "outputId": "cc5272d8-8360-43b7-d63c-9c18444da32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictive Parity Difference: 0.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QAHyVKB3Q7Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairlearn\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV86cB-MRJgg",
        "outputId": "409dd2cb-f7bf-48c3-cfde-d476c12cc31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.10.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
            "Downloading fairlearn-0.10.0-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.1/234.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.10.0\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "pegpkJKpRSwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E96wdISpRV9_",
        "outputId": "60bd277f-82ce-4c25-8024-5c835b2cac5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8866666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k9keRQ-bJHNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Sometimes, machine learning models can be unfair to certain groups of people.\n",
        "\n",
        "\n",
        "We want the model to treat everyone equally, regardless of their group (like gender or race).\n",
        "\n",
        "\n",
        "The ExponentiatedGradient method changes the importance of different pieces of training data to make the model fairer.\n",
        "\n",
        "\n",
        " This helps the model make fairer decisions for everyone."
      ],
      "metadata": {
        "id": "ecbRY7-mJHlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install fairlearn\n",
        "!pip install scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from fairlearn.metrics import MetricFrame, selection_rate\n",
        "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(1000, 10)\n",
        "y = np.random.randint(0, 2, 1000)\n",
        "sensitive_feature = np.random.randint(0, 2, 1000)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(\n",
        "X, y, sensitive_feature, test_size=0.2, random_state=0)\n",
        "classifier = LogisticRegression(solver='liblinear')\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "    # Measure fairness\n",
        "metric_frame = MetricFrame(metrics=accuracy_score, y_true=y_test, y_pred=y_pred, sensitive_features=sensitive_test)\n",
        "print(\"Metric Frame:\")\n",
        "print(metric_frame.by_group)\n",
        "\n",
        "    # Mitigate bias using ExponentiatedGradient\n",
        "mitigator = ExponentiatedGradient(classifier, constraints=DemographicParity())\n",
        "mitigator.fit(X_train, y_train, sensitive_features=sensitive_train)\n",
        "y_pred_mitigated = mitigator.predict(X_test)\n",
        "\n",
        "    # Evaluate the mitigated classifier\n",
        "accuracy_mitigated = accuracy_score(y_test, y_pred_mitigated)\n",
        "print(f\"Mitigated Accuracy: {accuracy_mitigated}\")\n",
        "\n",
        "    # Measure fairness after mitigation\n",
        "metric_frame_mitigated = MetricFrame(metrics=accuracy_score, y_true=y_test, y_pred=y_pred_mitigated, sensitive_features=sensitive_test)\n",
        "print(\"Mitigated Metric Frame:\")\n",
        "print(metric_frame_mitigated.by_group)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlIoWKqmSF3G",
        "outputId": "d88b08ff-0115-499b-8649-fc898fb8318e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fairlearn in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Accuracy: 0.475\n",
            "Metric Frame:\n",
            "sensitive_feature_0\n",
            "0    0.438776\n",
            "1    0.509804\n",
            "Name: accuracy_score, dtype: float64\n",
            "Mitigated Accuracy: 0.495\n",
            "Mitigated Metric Frame:\n",
            "sensitive_feature_0\n",
            "0    0.448980\n",
            "1    0.539216\n",
            "Name: accuracy_score, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NV1VHKOdSqlH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}